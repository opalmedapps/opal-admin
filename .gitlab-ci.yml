# set up
# see: https://docs.gitlab.com/ee/ci/caching/#cache-python-dependencies
# Change pip's cache directory to be inside the project directory since we can
# only cache local items.
variables:
  PIP_CACHE_DIR: "$CI_PROJECT_DIR/.cache/pip"
  MARIADB_ROOT_PASSWORD: $DB_ROOT_PASSWORD
  # ensure that user has permissions for test DB to be used by pytest
  MARIADB_DATABASE: test_$DB_NAME
  MARIADB_USER: $DB_USER
  MARIADB_PASSWORD: $DB_PASSWORD

default:
  image: $CI_REGISTRY_IMAGE:$CI_COMMIT_REF_SLUG
  before_script:
    - uname -a
    - python --version
    # set up env file for DB service
    # use sample env file
    - cp .env.sample .env
    - sed -i "s/^DATABASE_HOST=.*/DATABASE_HOST=mariadb/" .env
    - sed -i "s/^DATABASE_NAME=.*/DATABASE_NAME=$DB_NAME/" .env
    - sed -i "s/^DATABASE_USER=.*/DATABASE_USER=$DB_USER/" .env
    - sed -i "s/^DATABASE_PASSWORD=.*/DATABASE_PASSWORD=$DB_PASSWORD/" .env
    # set up legacy DB connection
    # reuse the same database as for the other tests to make it easier
    - sed -i "s/^LEGACY_DATABASE_HOST=.*/LEGACY_DATABASE_HOST=mariadb/" .env
    - sed -i "s/^LEGACY_DATABASE_PORT=.*/LEGACY_DATABASE_PORT=3306/" .env
    - sed -i "s/^LEGACY_DATABASE_NAME=.*/LEGACY_DATABASE_NAME=OpalDB/" .env
    - sed -i "s/^LEGACY_DATABASE_USER=.*/LEGACY_DATABASE_USER=$DB_USER/" .env
    - sed -i "s/^LEGACY_DATABASE_PASSWORD=.*/LEGACY_DATABASE_PASSWORD=$DB_PASSWORD/" .env
    # set up QuestionnaireDB connection as well
    - sed -i "s/^LEGACY_QUESTIONNAIRE_DATABASE_NAME=.*/LEGACY_QUESTIONNAIRE_DATABASE_NAME=QuestionnaireDB/" .env
    # generate secret key
    - SECRET_KEY=$(python -c "import secrets; print(secrets.token_urlsafe())")
    - sed -i "s/^SECRET_KEY=.*/SECRET_KEY=$SECRET_KEY/" .env


stages:
  - Build
  - Static Analysis
  - Checks
  - Test
  - Documentation

.default_needs:
  needs:
    - job: build image

build image:
  stage: Build
  image: docker:20.10.24
  services:
    - docker:20.10.24-dind
  variables:
    # Use TLS https://docs.gitlab.com/ee/ci/docker/using_docker_build.html#tls-enabled
    DOCKER_HOST: tcp://docker:2376
    DOCKER_TLS_CERTDIR: "/certs"
  before_script:
    # login to CI registry: https://docs.gitlab.com/ee/ci/docker/using_docker_build.html#option-1-run-docker-login
    - echo $CI_REGISTRY_PASSWORD | docker login $CI_REGISTRY --username $CI_REGISTRY_USER --password-stdin
  script:
    - export IMAGE_REPOSITORY=$CI_REGISTRY_IMAGE
    # create an image tagged with the branch or tag name
    - export IMAGE_BRANCH=$IMAGE_REPOSITORY:$CI_COMMIT_REF_SLUG
    # plus for the default branch create a latest and commit tag
    # the commit tag allows us to get images of previous commits in case of problems
    - export IMAGE_LATEST=$IMAGE_REPOSITORY:latest
    - export IMAGE_COMMIT=$IMAGE_REPOSITORY:$CI_COMMIT_SHA
    # make use of the Docker cache to speed up building
    # see: https://docs.gitlab.com/ee/ci/docker/using_docker_build.html#make-docker-in-docker-builds-faster-with-docker-layer-caching
    - docker pull $IMAGE_LATEST || true
    - docker pull $IMAGE_BRANCH || true
    - docker build --cache-from $IMAGE_BRANCH --cache-from $IMAGE_LATEST --tag $IMAGE_BRANCH --tag $IMAGE_LATEST --tag $IMAGE_COMMIT .
    - docker push $IMAGE_BRANCH
    - |
      if [[ "$CI_COMMIT_BRANCH" == "$CI_DEFAULT_BRANCH" ]]; then
        echo "Running on default branch. Pushing latest and commit tags..."
        docker push $IMAGE_LATEST
        docker push $IMAGE_COMMIT
      fi

flake8:
  stage: Static Analysis
  extends:
    - .default_needs
  script:
    - flake8 --version
    # install plugin to produce code climate report
    - pip install flake8-gl-codeclimate
    # don't fail if there are errors so the result can also be printed to the console for logs
    - flake8 --format gl-codeclimate --output-file gl-code-quality-report.json || true
    # fail if JSON file does not contain empty array
    - cat gl-code-quality-report.json | grep -q "\[\]"
  artifacts:
    when: always
    reports:
      codequality: gl-code-quality-report.json

mypy:
  stage: Static Analysis
  extends:
    - .default_needs
  script:
    # install plugin to produce code climate report
    - pip install mypy-gitlab-code-quality
    - mypy --version
    # export output and don't fail if there are errors
    - mypy opal/ --no-error-summary > mypy-out.txt || true
    - PYTHONHASHSEED=0 mypy-gitlab-code-quality < mypy-out.txt > codequality.json
     # fail if JSON file does not contain empty array
    - cat codequality.json | grep -q "\[\]"
  artifacts:
    when: always
    reports:
      codequality: codequality.json

markdownlint:
  stage: Static Analysis
  extends:
    - .default_needs
  image:
    name: davidanson/markdownlint-cli2:v0.8.1
    # overwrite default entrypoint (which is a call to markdownlint-cli2)
    entrypoint: [""]
  # this is not a Python script so we don't need to do all this extra stuff
  before_script:
    - markdownlint-cli2 --version
  script:
    # use the config file that is stored outside the root
    - markdownlint-cli2-config .gitlab/markdownlint/.markdownlint-cli2.yaml "**/*.md" "#.venv"
  artifacts:
    when: always
    reports:
      codequality: markdownlint-cli2-codequality.json

test:
  stage: Test
  extends:
    - .default_needs
  # set up DB service only for the test job since it is not used by others
  services:
    - mariadb:10.6.15-focal
  script:
    # create additional DBs for legacy DB tests (OpalDB & QuestionnaireDB)
    - apt update && apt-get install -y default-mysql-client
    - MYSQL_PWD=$DB_ROOT_PASSWORD mysql -uroot -hmariadb -e "GRANT ALL PRIVILEGES ON \`test_OpalDB\`.* TO \`$MARIADB_USER\`@\`%\`;"
    - MYSQL_PWD=$DB_ROOT_PASSWORD mysql -uroot -hmariadb -e "GRANT ALL PRIVILEGES ON \`test_QuestionnaireDB\`.* TO \`$MARIADB_USER\`@\`%\`;"
    - pytest --version
    # -m "" runs all tests, even the ones marked as slow
    - coverage run -m pytest -m "" --junitxml=report.xml
  artifacts:
    when: always
    reports:
      junit: report.xml
    paths:
      - .coverage

coverage:
  stage: Test
  script:
    # allow XML creation to fail to be able to parse coverage out of text report
    - coverage xml || true
    - coverage report
  needs:
    - job: test
  coverage: '/^TOTAL.+?(\d+.\d+\%)$/'
  # min coverage is set to 100, allow job to fail in order to signal that the coverage dropped
  # it does not mean it always has to be fixed
  allow_failure: true
  artifacts:
    when: always
    reports:
      coverage_report:
        coverage_format: cobertura
        path: coverage.xml

django migrations:
  stage: Checks
  extends:
    - .default_needs
  script:
    # Missing migrations
    - echo "Checking that there are no model changes for which there is no migration..."
    - python manage.py makemigrations --dry-run --check

django translations:
  stage: Checks
  extends:
    - .default_needs
  script:
    # install dependencies for makemessages and git diff
    - apt update && apt-get install -y gettext git
    # Missing translation file updates
    - echo "Checking that translation files have been updated ..."
    - python manage.py makemessages --add-location file -l fr
    # due to git LFS the LFS-tracked files show up in the diff, limit the diff to only .po files
    - git diff --ignore-matching-lines=POT-Creation-Date --exit-code *.po

django translations fuzzy:
  stage: Checks
  extends:
    - .default_needs
  # this is not a Python script so we don't need to do all this extra stuff from the default before_script
  before_script:
    - python --version
  script:
    # Ensure there are no fuzzy translation strings
    - echo "Checking for presence of fuzzy translation strings (need updates) ..."
    - FUZZY_STRINGS=$(grep --include=\*.po -rnw './opal' -e "#, fuzzy" -B01 -A02 | grep -E '#[~]?\| msgid' -B02 -A01 || true)
    - >
        if [[ $FUZZY_STRINGS ]]; then
          echo "$FUZZY_STRINGS"
          (! echo "$FUZZY_STRINGS" | grep -q .)
        fi


django translations commented:
  stage: Checks
  extends:
    - .default_needs
  # this is not a Python script so we don't need to do all this extra stuff from the default before_script
  before_script:
    - python --version
  script:
    # Ensure there are no commented out translation strings
    - echo "Checking for presence of commented out translation strings ..."
    - COMMENTED_STRINGS=$(grep --include=\*.po -rnw './opal' -e "#~ msgid" -B01 -A03 || true)
    - >
        if [[ $COMMENTED_STRINGS ]]; then
          echo "$COMMENTED_STRINGS"
          (! echo "$COMMENTED_STRINGS" | grep -q .)
        fi

django auto-named migrations:
  stage: Checks
  extends:
    - .default_needs
  # this is not a Python script so we don't need to do all this extra stuff from the default before_script
  before_script:
    - python --version
  script:
    # Prevent auto-named migrations
    - echo "Checking that migrations are not auto-named ..."
    # See: https://adamj.eu/tech/2020/02/24/how-to-disallow-auto-named-django-migrations/
    # Return exit code of 1 if results found, 0 otherwise
    # See: https://serverfault.com/q/225798 and https://stackoverflow.com/a/53753605
    - (! find ./opal -regex '.*/migrations/.*_auto_.*\.py$' | grep -q .)

django checks:
  stage: Checks
  extends:
    - .default_needs
  script:
    # Run checks to be sure we follow all django's best practices:
    - echo "Checking that all Django checks pass ..."
    - python manage.py check --fail-level WARNING

django template validation:
  stage: Checks
  extends:
    - .default_needs
  script:
    # Check templates
    - echo "Validating templates ..."
    - python manage.py validate_templates

# Try building the documentation site to ensure there are no issues
build docs:
  stage: Documentation
  script:
    - pip install -r requirements/docs.txt
    - mkdocs --version
    # abort on warnings to catch invalid cross-references
    - mkdocs build --strict
  # cannot restrict to only merge requests due to the following issue:
  # https://gitlab.com/gitlab-org/gitlab/-/issues/31310
  needs:
    - job: markdownlint

# Publish docs to GitLab Pages
# see: https://squidfunk.github.io/mkdocs-material/publishing-your-site/#gitlab-pages
#
pages:
  stage: Documentation
  only:
    - main
  script:
    - pip install --upgrade pip
    - pip install -r requirements/docs.txt
    - mkdocs build --site-dir public
  artifacts:
    paths:
      - public
  needs:
    - build docs
